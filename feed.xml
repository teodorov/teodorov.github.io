<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://teodorov.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://teodorov.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-11-14T10:44:05+00:00</updated><id>https://teodorov.github.io/feed.xml</id><title type="html">blank</title><subtitle>Cip&apos;s homepage </subtitle><entry><title type="html">MBSE Challenges</title><link href="https://teodorov.github.io/blog/2024/mbse_challenges/" rel="alternate" type="text/html" title="MBSE Challenges"/><published>2024-11-06T00:00:00+00:00</published><updated>2024-11-06T00:00:00+00:00</updated><id>https://teodorov.github.io/blog/2024/mbse_challenges</id><content type="html" xml:base="https://teodorov.github.io/blog/2024/mbse_challenges/"><![CDATA[<p>MBSE promises to facilitate communication via technology (models &amp; tools) amongst stakeholders, and different engineering disciplines in the system engineering process.</p> <p>In the following I want to point out 10 challenges that need to be addressed if we want to achieve the full potential of Model-Based Systems Engineering (MBSE).</p> <p>In focusing on MBSE, we delve into challenges that are distinct from broader systems engineering concerns, as MBSE itself becomes the subject of study rather than the system being designed.</p> <p>MBSE challenges pertain to refining the methodologies, tools, and frameworks that make MBSE robust, scalable, and applicable across various domains, while traditional systems engineering challenges center on the practicalities of designing, developing, and delivering complex systems in response to specific stakeholder requirements.</p> <p>By addressing MBSE-specific challenges, we aim to strengthen MBSE as a discipline, ensuring it can effectively support and enhance systems engineering practices. At the same time, applying MBSE in real-world scenarios provides valuable insights into its limitations, revealing areas where further refinement is necessary to maximize its impact in complex system development.</p> <p><img src="/assets/img/mbse_challenges.svg" alt="challenges diagram" class="img-fluid rounded z-depth-1"/></p> <p>These challenges emerge from studying and developing MBSE as a discipline. They focus on the theoretical, methodological, and practical aspects that make MBSE effective and scalable as an approach to complex system design.</p> <h3 id="c1-formalization-of-models-and-languages--their-composition"><a id="C1">C1</a>. Formalization of Models and Languages &amp; Their Composition</h3> <p>At its core, MBSE relies on rigorous model formalization to enable consistency, composability, and correctness across complex systems. Yet, without a solid formal foundation for models and their languages, MBSE can devolve into fragmented representations that lack robustness. Formalized syntax and semantics across modeling languages, alongside methods for safe model composition, are fundamental to creating resilient, interoperable MBSE frameworks. Ensuring these fundamentals is crucial, especially in high-stakes domains where ambiguities in model definitions can lead to critical system vulnerabilities and operational breakdowns.</p> <h3 id="c2-breaking-through-model-heterogeneity-and-tool-fragmentation"><a id="C2">C2</a>. Breaking Through Model Heterogeneity and Tool Fragmentation</h3> <p>MBSE promises unified, coherent design, yet current practices often force engineers to juggle disparate tools and muddled abstractions, compromising model coherence. Systems built with SysML, NAF, BPMN, and specialized simulations too often form disconnected silos, diluting MBSE’s potential. Effective MBSE demands an integrated ecosystem, where models interoperate seamlessly across domains and tools, replacing chaotic handoffs with a cohesive model federation. In defense and other high-stakes contexts, this alignment is essential to avoid costly errors and ensure mission coherence. Model federation approaches <a href="#1">[1]</a>, such as <a href="https://openflexo.org/">OpenFlexo</a> <a href="#2">[2]</a> tackle this problem by embraching heterogeneity and focusing on building semantic links between the abstractions and the tools. In my work, <a href="/_pages/hdr.md">G∀min∃</a>, around behavioral analysis of <em>potentially</em> heterogeneous specification I argue towards establishing these semantics links at the semantic-level (not a syntactic level) by using the language semantics as ‘inteligent’ mediators that brings meaning to data, viewed as a syntactic structure.</p> <h3 id="c3-ensuring-end-to-end-traceability-for-evolving-requirements"><a id="C3">C3</a>. Ensuring End-to-End Traceability for Evolving Requirements</h3> <p>Traceability is more than a documentation task—it’s the backbone of MBSE’s adaptability, linking evolving requirements with every design decision and system component. In fast-paced, operationally intense fields, traceability is essential to maintain coherence as systems grow and adapt. Without a robust framework to track these dependencies, MBSE risks drifting from stakeholder needs. Clear lineage tracking transforms MBSE models from static plans to dynamic, responsive roadmaps, ensuring every change is justified, verifiable, and strategically aligned. The notion of tracability here goes beyond the tracability as a system-centric requirement evolution technology, focusing on the evolutionary nature of the whole set of design artifacts, tools, practices leading to the even bigger challenge of mastering evolution <a href="#2">[2]</a>.</p> <h3 id="c4-embedding-validation-and-verification-vv-in-experimental-and-validity-frames"><a id="C4">C4</a>. Embedding Validation and Verification (V&amp;V) in Experimental and Validity Frames</h3> <p>MBSE’s strength is in validating and verifying system behavior before real-world deployment, but too many approaches fall short. Experimental and validity frames <a href="#3">[3]</a> provide structured ways to assess whether model results match real-world scenarios—an especially critical factor in defense, where accuracy can impact mission success. This is more than a checkbox—it’s a methodical framework for aligning simulations with practical, real-world applications. Without explicit validation frames, MBSE models risk becoming isolated theoretical exercises, detached from operational relevance. At a conceptual level we can say that the validity frames reify and finely caracterise a link between the reality, the model that abstract it, and the modeling intentions (the questions that need to be answered by the model). From this perspective a validity frame tels us when it is sound to trust the answers that we get from the model. The presence of ad-hoc heterogeneity <a href="#C2">C2</a>, in today’s MBSE approaches, renders the model verification and validation even more challenging.</p> <h3 id="c5-establishing-a-reliable-authoritative-source-of-truth-asot"><a id="C5">C5</a>. Establishing a Reliable Authoritative Source of Truth (ASoT)</h3> <p>MBSE requires a single, authoritative source of truth (ASoT) to prevent outdated or misaligned models from sabotaging projects. Yet, many frameworks lack the model management strategy to uphold this, risking breakdowns in coherence. A strong ASoT enables teams to work confidently with validated, up-to-date models, ensuring every iteration cascades systematically across the design landscape. Without rigorous ASoT, engineering teams are left wrestling with fragmented updates and misaligned versions, particularly perilous in mission-critical systems. This problem is significantly agravated by the lack of crisp formalization <a href="#C1">C1</a>, the ad-hoc heterogeneity management <a href="#C2">C2</a>, the insuffient understanding of model &amp; tool evolution <a href="#C3">C3</a>, and the missing solutions to the verification and validations challenges <a href="#C4">C4</a>.</p> <h3 id="c6-scaling-mbse-for-complex-systems-without-model-overload"><a id="C7">C6</a>. Scaling MBSE for Complex Systems without Model Overload</h3> <p>As systems grow more complex, MBSE must scale to handle intricate details without overwhelming teams. Techniques like modularization, abstraction layers, and model reduction can keep teams from drowning in detail, even as they tackle sprawling, interconnected subsystems. In defense, the stakes are even higher, as model overload can lead to operational blind spots. Smart, scalable practices in MBSE help teams maintain focus on the big picture while keeping track of critical details. Approaches such as <a href="https://moldabledevelopment.com/">Moldable Development</a> and <a href="http://www.humane-assessment.com/">Humane-assessment</a> could prove instrumental for guiding the decision making process without requiring the manual exploration of a large web of interconnected heterogeneous abstractions.</p> <h3 id="c7-achieving-a-unified-mbse-methodology-to-replace-fragmented-practices"><a id="C6">C7</a>. Achieving a Unified MBSE Methodology to Replace Fragmented Practices</h3> <p>Too often, MBSE implementation is fragmented, forcing engineers to juggle incompatible tools and shifting paradigms. This fragmentation undermines collaboration, confuses stakeholders, and drains resources as teams attempt to reconcile mismatched frameworks. A unified MBSE methodology—one that harmonizes interoperability, traceability, and model validation—enables engineers to focus on system-specific reasoning rather than grappling with clashing tools. In critical fields like defense, where system coherence can make or break a mission, harmonization is essential to transform MBSE from a patchwork of tools into a cohesive, high-impact methodology.</p> <h3 id="c8-education-and-adoption-overcoming-the-steep-learning-curve"><a id="C8">C8</a>. Education and Adoption: Overcoming the Steep Learning Curve</h3> <p>MBSE demands a fresh mindset in systems development, but the learning curve is steep, and expertise is limited. Educating engineers in MBSE practices, transitioning teams from traditional approaches, and fostering interdisciplinary understanding are all significant barriers to MBSE adoption. As MBSE permeates industries like defense, where roles are often highly specialized, bridging knowledge gaps and building interdisciplinary MBSE fluency are essential to harnessing its full potential. Without effective education and adoption strategies, MBSE risks remaining a niche approach, out of reach for many teams who could benefit from its structured, model-driven approach. In <a href="#2">[2]</a>, the authors identifies the <strong>preservation of existing practices</strong> as a technological challenge that requires a shift in focus from <em>the users need to adopt tools</em> towards <em>the tool provider need to accomodate existing user practices</em>. From this perspective the <em>interoperability</em> challenge become <em>how to ensure semantic interoperability while striving to preserve existing practices</em>. While the authors of <a href="#2">[2]</a> emphasize on preserving <em>all</em> existing practices, rationality dictates that we should preserve only the benefic existing practices, and facilitate the elimination of detrimental ones.</p> <h3 id="c9-balancing-formal-rigor-with-human-centered-qualitative-aspects"><a id="C9">C9</a>. Balancing Formal Rigor with Human-Centered Qualitative Aspects</h3> <p>MBSE traditionally emphasizes formal rigor to ensure precision, correctness, and reliability. However, this focus can unintentionally stifle creativity and frustrate users, especially when the tools and methods become overly constraining. Striking a balance between formal rigor and qualitative insights allows MBSE to embrace a more human-centered approach, one that empowers rather than limits engineers <a href="#4">[4]</a>. By incorporating flexibility and fostering interpretative thinking, MBSE can evolve to support not only structured, repeatable processes but also the intuition and creativity essential to complex system design. This balance is critical to making MBSE both robust and adaptable to the nuanced needs of its users.</p> <h3 id="c10-absence-of-benchmarking-standards-for-objective-evaluation"><a id="C10">C10</a>. Absence of Benchmarking Standards for Objective Evaluation</h3> <p>The vast diversity of systems, domains, and stakeholder cultures makes it challenging to establish standardized benchmarks for evaluating MBSE practices and tools. This lack of benchmarking hinders both research and industry by clouding our view of the state of the art and impeding clear comparisons between methodologies and technologies. Researchers struggle to gauge what progress has been made and what gaps remain, while practitioners face subjective, often arbitrary decisions when selecting tools and technologies. Without clear benchmarks, choices are too often based on marketing, personal preferences, or past experiences, rather than an objective assessment of each tool’s capabilities relative to specific project needs. Establishing benchmarking frameworks would enable both the academic and industrial communities to make more informed, strategic decisions about MBSE solutions.</p> <p>The absence of clear benchmarks and foundational focus traps MBSE research in an endless cycle of reinventing the wheel with each new tool or abstraction. Instead of advancing core methodologies, the community often chases superficial differences, losing sight of the deeper challenges that would empower tool vendors to handle system-specific diversity with precision and adaptability.</p> <p>These challenges underscores the foundational need for formalized models and model composition, highlighting how MBSE can only reach its potential through rigorous structure, coherence, and a unified methodology that cuts through complexity.</p> <h2 id="references">References</h2> <p><a id="1">[1]</a> Moussa Amrani, Rakshit Mittal, Miguel Goulão, Vasco Amaral, Sylvain Guérin, Salvador Martínez, Dominique Blouin, Anish Bhobe, and Yara Hallak. 2024. A Survey of Federative Approaches for Model Management in MBSE. In Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems (MODELS Companion ‘24). Association for Computing Machinery, New York, NY, USA, 990–999. https://doi.org/10.1145/3652620.3688221</p> <p><a id="2">[2]</a> Jean-Christophe Bach, Antoine Beugnard, Joël Champeau, Fabien Dagnat, Sylvain Guérin, and Salvador Martínez. 2024. 10 years of Model Federation with Openflexo: Challenges and Lessons Learned. In Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems (MODELS ‘24). Association for Computing Machinery, New York, NY, USA, 25–36. https://doi.org/10.1145/3640310.3674084</p> <p><a id="3">[3]</a> R. Mittal, R. Eslampanah, L. Lima, H. Vangheluwe and D. Blouin, “Towards an Ontological Framework for Validity Frames,” 2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C), Västerås, Sweden, 2023, pp. 801-805, doi: 10.1109/MODELS-C59198.2023.00128.</p> <p><a id="4">[4]</a> Meadows, D., Richardson, J., &amp; Bruckmann, G. (1982). Groping in the Dark: The First Decade of Global Modelling. Chichester, UK: John Wiley &amp; Sons. ISBN 9780471100270</p>]]></content><author><name></name></author><category term="research"/><category term="MBSE"/><category term="MBSE"/><summary type="html"><![CDATA[Challenges when considering MBSE as a subject of study]]></summary></entry><entry><title type="html">Verify Function Context Diagram</title><link href="https://teodorov.github.io/blog/2024/verify_function/" rel="alternate" type="text/html" title="Verify Function Context Diagram"/><published>2024-11-05T00:00:00+00:00</published><updated>2024-11-05T00:00:00+00:00</updated><id>https://teodorov.github.io/blog/2024/verify_function</id><content type="html" xml:base="https://teodorov.github.io/blog/2024/verify_function/"><![CDATA[<h2 id="context">Context</h2> <p>In the development and deployment of complex systems, <strong>verifying whether a system meets a given specification</strong> is fundamental to ensuring its correct and reliable operation. Specifications outline the intended functionality, safety requirements, and other performance criteria that a system must meet. Verifying a system against these specifications is vital not only to ensure quality and correctness but also to comply with regulatory standards, minimize risks, and provide confidence to stakeholders that the system will operate as intended. Given the complexity of modern systems, verification can range from manual, human-driven checks to fully automated, computationally intensive processes.</p> <h2 id="problems">Problems</h2> <p>System verification is inherently challenging due to the complexity of specifications and the variety of system behaviors. Verifying that a system model satisfies its specification is often resource-intensive and may require sophisticated techniques to produce reliable conclusions. Additionally, verifying systems under realistic constraints — with finite time, computational power, and human resources — introduces further complications. A key challenge is ensuring that the specification accurately reflects the specification author’s intent, requiring careful concretization and idea-capturing to translate high-level concepts into explicit, verifiable requirements. Equally fundamental is the need to obtain a faithful model of the actual system through an abstraction process that accurately reflects the system’s behaviors and structure. Verification outputs are critical for decision-making and need to be clear, actionable, and trustworthy. Moreover, the adversarial context, where malicious actors may attempt to bypass or exploit verification steps, demands additional resilience from the verification process itself.</p> <h2 id="purpose-of-the-verify-function">Purpose of the Verify Function</h2> <p>The <strong>verify</strong> function is designed to systematically evaluate whether a system model satisfies a given specification. The function uses both human and computational resources in varying proportions, depending on the verification needs and resources available. By processing inputs such as specifications, system models, verification parameters (hypotheses, resource allocation, and precision), and optionally, historical data, the function aims to deliver reliable outcomes. <strong>The main goal is to determine whether the system meets its requirements</strong>, doesn’t meet them, or if the result is indeterminate due to certain limitations. It also provides structured feedback in the form of verification results, intermediate insights, and recommended actions to aid decision-makers in addressing verification findings.</p> <h2 id="description-of-the-verify-function">Description of the Verify Function</h2> <p>A generic <strong>verify</strong> function context diagram is shown in the following figure:</p> <p><img src="/assets/img/VerifyFunction.png" alt="verify function" class="img-fluid rounded z-depth-1"/></p> <p>The <strong>verify</strong> function operates as follows:</p> <ol> <li><strong>Primary Inputs</strong>: <ul> <li><strong>Specification</strong>: The set of requirements and constraints that define acceptable system behavior.</li> <li><strong>System Model</strong>: A representation of the system to be verified, which may include detailed structures, behaviors, and states.</li> <li><strong>Verification Parameters</strong>: Settings that define the scope and depth of verification, including assumptions, resource allocations, and precision requirements.</li> <li><strong>Historical Data</strong> (optional): Previous verification outcomes that help refine the process.</li> </ul> </li> <li><strong>Verification Process</strong>: <ul> <li>The function applies verification techniques with varying degrees of human intervention and automation. On one end, manual verification involves human inspection without computational support. On the other, fully automated verification leverages algorithms and computational power to achieve the results with minimal human input.</li> </ul> </li> <li><strong>Primary Outputs</strong>: <ul> <li>The verification output is structured as a tuple <code class="language-plaintext highlighter-rouge">(conclusion, witness)</code>, with the following three possibilities: <ul> <li><strong>(OK, justification)</strong>: The system satisfies the specification, with a justification explaining the compliance. In some cases, this justification may be unavailable.</li> <li><strong>(Fail, counter-example)</strong>: The system does not meet the specification, with a counter-example highlighting the failure. Sometimes, the counter-example might be missing.</li> <li><strong>(Unknown, explanation)</strong>: Verification cannot determine compliance, with an explanation outlining the reasoning. This explanation might include traceability details, such as assumptions or verification paths. Sometimes, the explanation itself might be unknown if the limitations of the verification are unclear.</li> </ul> </li> </ul> </li> <li><strong>Complementary Outputs</strong>: <ul> <li><strong>Intermediate Results</strong>: For complex systems, verification may take time. Periodic checkpoints or incremental findings allow stakeholders to monitor progress or understand partial conclusions.</li> <li><strong>Suggested Actions &amp; Recommendations</strong>: When verification results indicate a failure or uncertainty, the function can suggest next steps, such as revising the model or exploring specific areas of the specification.</li> <li><strong>Metrics</strong>: Information on verification performance, resource usage, and complexity helps optimize future verification tasks and provides insight into verification robustness.</li> </ul> </li> </ol> <h2 id="challenges">Challenges</h2> <p>The <strong>verify</strong> function faces several key challenges:</p> <ol> <li> <p><strong>Resource Constraints</strong>: Balancing human and computational resources effectively is challenging, especially for complex systems requiring high precision or thorough exploration of states.</p> </li> <li> <p><strong>Scalability and Complexity</strong>: As system models grow in size and complexity, verification becomes exponentially more challenging, sometimes resulting in incomplete justifications or missing counter-examples.</p> </li> <li> <p><strong>Traceability and Transparency</strong>: Verification results must be traceable to specific parameters and assumptions to be useful. This requires detailed reporting and logging, which can be difficult to maintain in large systems or automated processes.</p> </li> <li> <p><strong>Handling Ambiguity</strong>: Specifications may sometimes be ambiguous or incomplete, leading to “Unknown” conclusions. Verification must have mechanisms to report such ambiguities clearly, ensuring they are addressed in future verification cycles.</p> </li> <li> <p><strong>Security and Robustness</strong>: Adversarial stakeholders may attempt to bypass or manipulate the verification process. The verification function must be resilient against such threats, ensuring that results cannot be tampered with and that outputs accurately reflect the system’s compliance status.</p> </li> <li> <p><strong>Specification Intent and Explicitation</strong>: While typically considered outside the scope of the verification function, a significant challenge in verification is ensuring that the specification truly captures the intent of its authors. This process of explicitation—transforming ideas into concrete, precise requirements—requires careful thought and alignment before verification can be meaningfully applied.</p> </li> <li> <p><strong>Faithful System Model Abstraction</strong>: Another prerequisite for reliable verification, generally considered external to the verify function, is obtaining a system model that faithfully represents the actual system. This abstraction process, capturing essential behaviors and structures without omitting critical aspects, is essential to avoid mismatches between the model and the real system that could compromise verification results.</p> </li> </ol> <p>Certainly. Here’s a section that incorporates these thoughts and presents the elements you consider orthogonal to the core purpose of the <strong>verify</strong> function:</p> <h2 id="considerations-on-the-context-diagram">Considerations on the Context Diagram</h2> <p>While the presented context diagram for the <strong>verify</strong> function provides a generic view, there are several aspects included that seem somewhat orthogonal to the function’s core purpose:</p> <ol> <li> <p><strong>Historical Data</strong>: Although historical data can be helpful, it ideally should be collected by an encapsulating process or function that manages data over multiple verification cycles. Rather than feeding historical data directly into the <strong>verify</strong> function, it could be better organized as a higher-level process feeding back relevant insights into the function via refined verification parameters. This separation would help keep the function focused on the immediate verification task rather than managing historical context.</p> </li> <li> <p><strong>Intermediate Results</strong>: The generation of intermediate results is another element that feels tangential to the primary verification objective. In principle, intermediate insights could be obtained by externally observing or inspecting the state of the verification process as it runs, rather than being managed as an explicit output of the function. This approach keeps the function streamlined and allows external observers or monitoring systems to capture and log incremental states without overcomplicating the function itself.</p> </li> <li> <p><strong>Metrics (Resource Usage, Performance, etc.)</strong>: Metrics such as resource usage, memory consumption, and performance statistics are similarly external to the core purpose of verification, which is focused on evaluating compliance with specifications. These metrics are more aligned with observing the underlying resources—human or computational—that facilitate verification. Monitoring systems could observe and log this information independently, through an external “resource substrate,” rather than having the verification function track it directly. This way, the <strong>verify</strong> function remains focused, with performance metrics collected via external instrumentation.</p> </li> </ol> <p>These elements (historical data, intermediate results, and resource metrics) could be observed and managed at a meta-level, perhaps through something akin to a <em>digital twin</em> or a <em>wrapper</em> for the <strong>verify</strong> function. Such a meta-layer could provide the necessary observability and memory to track historical runs, monitor ongoing state, and capture resource data without complicating the primary function. In this sense, these elements could be viewed as <strong>meta-level components</strong> that, while useful, are not part of the core verification logic itself.</p>]]></content><author><name></name></author><category term="research"/><category term="verification"/><category term="verification"/><category term="context diagram"/><category term="MBSE"/><summary type="html"><![CDATA[A generic discussion on the Verify function & its context]]></summary></entry><entry><title type="html">Execution Sequencing based on the G∀min∃ SLI</title><link href="https://teodorov.github.io/blog/2024/sli-sequencer/" rel="alternate" type="text/html" title="Execution Sequencing based on the G∀min∃ SLI"/><published>2024-10-21T00:00:00+00:00</published><updated>2024-10-21T00:00:00+00:00</updated><id>https://teodorov.github.io/blog/2024/sli-sequencer</id><content type="html" xml:base="https://teodorov.github.io/blog/2024/sli-sequencer/"><![CDATA[<p>In a <a href="../gamine_sli">previous post</a> I have discussed the <a href="../gamine_sli"><strong>G∀min∃ Semantic Language Interface (SLI)</strong></a>, which offers the capacity to capture any operational semantics while exposing the non-determinism. Here we will look at how we can use the Semantic Language Interface for language execution.</p> <h2 id="execution-of-sli-semantics-with-the-sequencer">Execution of SLI Semantics with the Sequencer</h2> <p>The G∀min∃ Semantic Language Interface (SLI) employs a Sequencer to navigate through configurations based on defined actions. The execution process is outlined in the following pseudocode:</p> <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="nc">Sequencer</span><span class="o">(</span><span class="n">sli</span><span class="o">)</span>
    <span class="n">current</span> <span class="k">=</span> <span class="nv">sli</span><span class="o">.</span><span class="py">initial</span><span class="o">.</span><span class="py">any</span>
    <span class="nf">while</span> <span class="o">(</span><span class="n">current</span> <span class="o">!=</span> <span class="nc">NULL</span><span class="o">)</span>
        <span class="n">action</span> <span class="k">=</span> <span class="nv">sli</span><span class="o">.</span><span class="py">actions</span><span class="o">(</span><span class="n">current</span><span class="o">).</span><span class="py">any</span>
        <span class="nf">if</span> <span class="o">(</span><span class="n">actions</span> <span class="o">==</span> <span class="nc">NULL</span><span class="o">)</span> <span class="n">break</span><span class="o">;</span>
        <span class="n">current</span><span class="k">=</span> <span class="nv">sli</span><span class="o">.</span><span class="py">execute</span><span class="o">(</span><span class="n">action</span><span class="o">,</span><span class="n">current</span><span class="o">).</span><span class="py">any</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>The Sequencer operates by first (line 2) selecting an initial configuration from the set defined by <code class="language-plaintext highlighter-rouge">sli.initial</code>, which serves as the starting point for the execution sequence.</p> <p>It then enters a loop (line 3) that continues as long as the current configuration is not <code class="language-plaintext highlighter-rouge">NULL</code>.</p> <p>During each iteration of the loop, the Sequencer processes the <code class="language-plaintext highlighter-rouge">current</code> configuration by arbitrarily selecting an action from the set of available actions for that configuration (line 4 – <code class="language-plaintext highlighter-rouge">sli.actions(current).any</code>). This selection leads the Sequencer down one arbitrary path through the state space for that particular execution.</p> <p>If no actions are available, the loop terminates (line 5); otherwise, the chosen action is executed (line 6 – <code class="language-plaintext highlighter-rouge">sli.execute(action,current)</code>), updating the current configuration one of the new configurations that result from the execution of the action (the choice here is again arbitrary).</p> <h2 id="deterministic-execution">Deterministic Execution</h2> <p>When the SLI exposes a deterministic semantics then the following proposition holds:</p> <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>    <span class="o">∀</span> <span class="n">a</span> <span class="n">c</span><span class="o">,</span> 
        <span class="o">|</span><span class="n">initial</span><span class="o">|</span> <span class="o">≤</span> <span class="mi">1</span>
    <span class="o">∧</span>   <span class="o">|</span><span class="n">actions</span> <span class="n">c</span><span class="o">|</span> <span class="o">≤</span> <span class="mi">1</span>
    <span class="o">∧</span>   <span class="o">|</span><span class="n">execute</span> <span class="n">a</span> <span class="n">c</span><span class="o">|</span> <span class="o">≤</span> <span class="mi">1</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>There is at most one <code class="language-plaintext highlighter-rouge">initial</code> configuration. For any configuration <code class="language-plaintext highlighter-rouge">c</code>, there is at most one action enabled. The execution in any action <code class="language-plaintext highlighter-rouge">a</code> enabled in a configuration <code class="language-plaintext highlighter-rouge">c</code>, there is at most one resulting configuration.</p> <p>In this case the Sequencer exposes the unique execution path through the linear state space.</p> <p><strong>Sidenote</strong>: If for an arbitrary configuration <code class="language-plaintext highlighter-rouge">c</code>, the cardinality of <code class="language-plaintext highlighter-rouge">action c</code> is 0, then the configuration <code class="language-plaintext highlighter-rouge">c</code> is a deadlock. Furthermore, for a configuration <code class="language-plaintext highlighter-rouge">c</code>, and the set of actions enabled in <code class="language-plaintext highlighter-rouge">c</code>, if the sum of cardinalities of all <code class="language-plaintext highlighter-rouge">execute aᵢ c</code> is 0 then again the configuration c is a deadlock. If, for some <code class="language-plaintext highlighter-rouge">a</code>, the cardinality of <code class="language-plaintext highlighter-rouge">execute a c</code> is zero then we say that the action <code class="language-plaintext highlighter-rouge">a</code> was <strong>blocked during execution</strong>.</p> <h2 id="condition-for-achieving-a-random-walk">Condition for Achieving a Random Walk</h2> <p>As a keen eye might have already noted, in general, the previous Sequencer will not perform a true <strong>random walk</strong>, but will expose only an arbitrary path through the configuration space.</p> <p>To obtain a random walk, the arbitrary choices need to be replaced by real random selections. That is the choice amongst the configurations and the enables actions should be uniformly distributed, giving each configuration and action an equal probability of being selected. That is not necessarily the case for the previous Sequencer, as it might, for instance, always choose the first configuration and/or enabled action.</p> <p>If the selection is truly random, then it offers the variety needed for a broader exploration of the state space and enables the execution to “wander” through the configurations space.</p> <p>Note also, that to explore various paths, the Sequencer would need to be executed multiple times, each time potentially selecting different actions and following different trajectories through the state space.</p> <h2 id="making-the-choices-more-explicit">Making the choices more explicit</h2> <p>To render the setup more generic, it will be nice to make the choices more explicit. To achieve that we will extract the configuration and action selection in a <code class="language-plaintext highlighter-rouge">determinization</code> operator, that itself is a SLI (in general). To be even finer we will specialize the SLI semantics to encode deterministic semantics, and the <code class="language-plaintext highlighter-rouge">determinization</code> operator will then be able to expose a deterministic semantics, that embeds the proof of determinism syntactically.</p> <p>Here is the definition of deterministic specialization of an SLI semantics:</p> <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="nf">deterministic_semantics</span><span class="o">(</span><span class="n">C</span> <span class="n">A</span><span class="o">)</span> <span class="o">≜</span>
    <span class="n">initial</span><span class="k">:</span> <span class="kt">Option</span> <span class="kt">C</span>              <span class="c1">//the set of initial configurations</span>
    <span class="n">actions</span><span class="k">:</span> <span class="kt">C</span> <span class="kt">→</span> <span class="kt">Option</span> <span class="kt">A</span>          <span class="c1">//the set of actions executable from a configuration</span>
    <span class="n">execute</span><span class="k">:</span> <span class="kt">A</span> <span class="kt">→</span> <span class="kt">C</span> <span class="kt">→</span> <span class="kt">Option</span> <span class="kt">C</span>      <span class="c1">//execute one action in one configuration</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">determinize</code> operator takes any subject semantics <code class="language-plaintext highlighter-rouge">s</code> as input as well as two choice policies, one for configurations and another one for actions. And implements the three functions required by the deterministic_semantics interface, as follows:</p> <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="nf">determinize</span><span class="o">(</span><span class="n">s</span><span class="o">,</span> <span class="n">configurationPolicy</span><span class="o">,</span> <span class="n">actionPolicy</span><span class="o">)</span> 
    <span class="k">def</span> <span class="nf">initial</span> 
        <span class="nf">configurationPolicy</span><span class="o">(</span><span class="nv">s</span><span class="o">.</span><span class="py">initial</span><span class="o">)</span>
    <span class="k">def</span> <span class="nf">actions</span>
        <span class="nf">actionPolicy</span><span class="o">(</span><span class="n">c</span><span class="o">,</span> <span class="nv">s</span><span class="o">.</span><span class="py">actions</span><span class="o">)</span>
    <span class="k">def</span> <span class="nf">execute</span>
        <span class="nf">configurationPolicy</span><span class="o">(</span><span class="nv">s</span><span class="o">.</span><span class="py">execute</span> <span class="n">a</span> <span class="n">c</span><span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>With these components available, we can revisit the previous Sequencer definition, and specialize it to the deterministic semantics, as follows:</p> <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="nf">deterministic_sequencer</span><span class="o">(</span><span class="n">sem</span><span class="k">:</span> <span class="kt">DeterministicSemantics</span><span class="o">)</span>
    <span class="n">current</span> <span class="k">=</span> <span class="nv">sem</span><span class="o">.</span><span class="py">initial</span>
    <span class="k">while</span> <span class="n">current</span> <span class="o">!=</span> <span class="n">none</span>
        <span class="n">action</span> <span class="k">=</span> <span class="nv">sem</span><span class="o">.</span><span class="py">action</span> <span class="n">current</span>
        <span class="nf">if</span> <span class="o">(</span><span class="n">action</span> <span class="o">==</span> <span class="n">none</span><span class="o">)</span> <span class="n">break</span><span class="o">;</span>
        <span class="n">current</span> <span class="k">=</span> <span class="nv">sem</span><span class="o">.</span><span class="py">execute</span><span class="o">(</span><span class="n">action</span><span class="o">,</span> <span class="n">current</span><span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>To <code class="language-plaintext highlighter-rouge">run</code> an arbitrary subject semantics <code class="language-plaintext highlighter-rouge">s</code> we only have to feed it through the <code class="language-plaintext highlighter-rouge">determinize</code> semantic operator along with the selection policies. Then, to execute, we can apply the <code class="language-plaintext highlighter-rouge">deterministic_sequencer</code> sequencer to the result of <code class="language-plaintext highlighter-rouge">determinize</code> (that lazily encodes a deterministic interpretation of the subject semantics). The following pseudocode illustrates these connections:</p> <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">run</span><span class="o">(</span><span class="n">sem</span><span class="k">:</span> <span class="kt">Semantics</span><span class="o">)</span><span class="k">:</span>
    <span class="kt">dsem</span> <span class="o">=</span> <span class="nf">determinize</span><span class="o">(</span><span class="n">sem</span><span class="o">,</span> <span class="n">cpolicy</span><span class="o">,</span> <span class="n">apolicy</span><span class="o">)</span>
    <span class="nf">deterministic_sequencer</span><span class="o">(</span><span class="n">dsem</span><span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>For example, the following lines encode three selection policies:</p> <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">any_policy</span><span class="o">(</span><span class="n">x</span><span class="k">:</span> <span class="kt">set</span> <span class="kt">X</span><span class="o">)</span><span class="k">:</span>
    <span class="kt">x.any</span>

<span class="k">def</span> <span class="nf">first_policy</span><span class="o">(</span><span class="n">x</span><span class="k">:</span> <span class="kt">set</span> <span class="kt">X</span><span class="o">)</span><span class="k">:</span>
    <span class="kt">x.first</span>

<span class="k">def</span> <span class="nf">random_policy</span><span class="o">(</span><span class="n">x</span><span class="k">:</span> <span class="kt">set</span> <span class="kt">X</span><span class="o">)</span><span class="k">:</span>
    <span class="kt">x.pick_random</span><span class="o">(</span><span class="kt">rnd</span><span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>where:</p> <ul> <li><code class="language-plaintext highlighter-rouge">any_policy</code>, which, if applied, provides the same results as the initial Sequencer.</li> <li><code class="language-plaintext highlighter-rouge">first_policy</code>, which, if applied, always chooses the first element amongst the configuration or actions.</li> <li><code class="language-plaintext highlighter-rouge">random_policy</code>, which, if applied, provides us with a random walk.</li> </ul>]]></content><author><name></name></author><category term="research"/><category term="semantics"/><category term="operational semantics"/><category term="semantics"/><category term="executable models"/><summary type="html"><![CDATA[a brief discussion on impacts of the G∀min∃ SLI on the language execution]]></summary></entry><entry><title type="html">G∀min∃ Semantic Language Interface</title><link href="https://teodorov.github.io/blog/2024/gamine_sli/" rel="alternate" type="text/html" title="G∀min∃ Semantic Language Interface"/><published>2024-10-20T00:00:00+00:00</published><updated>2024-10-20T00:00:00+00:00</updated><id>https://teodorov.github.io/blog/2024/gamine_sli</id><content type="html" xml:base="https://teodorov.github.io/blog/2024/gamine_sli/"><![CDATA[<p>The G∀min∃ Semantic Language Interface (SLI) is a framework designed to bridge the gap between executable specifications and behavior analysis tools. It captures the operational semantics of programming languages, called subject language in the following. Two key particularities of the SLI are:</p> <ul> <li><strong>exposes all non-determinism</strong> that might be present in the subject language;</li> <li>requires the definition of a <strong>step evaluation</strong> function, used to query the execution steps based on a <em>diagnosis language</em>.</li> </ul> <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="nc">SLI</span> <span class="o">≜</span>
    <span class="nf">semantics</span><span class="o">(</span><span class="n">C</span> <span class="n">A</span><span class="o">)</span> <span class="o">≜</span>
        <span class="n">initial</span><span class="k">:</span> <span class="kt">set</span> <span class="kt">C</span>              <span class="c1">//the set of initial configurations</span>
        <span class="n">actions</span><span class="k">:</span> <span class="kt">C</span> <span class="kt">→</span> <span class="kt">set</span> <span class="kt">A</span>          <span class="c1">//the set of actions executable from a configuration</span>
        <span class="n">execute</span><span class="k">:</span> <span class="kt">A</span> <span class="kt">→</span> <span class="kt">C</span> <span class="kt">→</span> <span class="kt">set</span> <span class="kt">C</span>      <span class="c1">//execute one action in one configuration</span>
    <span class="n">evaluate</span><span class="k">:</span> <span class="kt">E</span> <span class="kt">→</span> <span class="o">(</span><span class="kt">C</span> <span class="kt">x</span> <span class="o">(</span><span class="kt">A</span> <span class="kt">|</span> <span class="kt">Stutter</span><span class="o">)</span> <span class="kt">x</span> <span class="kt">C</span><span class="o">)</span> <span class="kt">→</span> <span class="kt">V</span>   <span class="c1">// questions on steps</span>
    <span class="n">reduce</span><span class="k">:</span> <span class="kt">R</span> <span class="kt">→</span> <span class="kt">C</span> <span class="kt">→</span> <span class="kt">⍺</span>               <span class="c1">// configuration reductions</span>
    <span class="nf">π</span> <span class="o">(</span><span class="n">C</span> <span class="n">A</span> <span class="n">V</span> <span class="o">⍺</span> <span class="n">T</span><span class="o">)</span> <span class="o">≜</span> <span class="o">⋯</span>               <span class="c1">// projections of the semantical entities</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>Let’s explore the key components of the SLI as defined:</p> <h2 id="semantics-definition">Semantics Definition</h2> <p>At the heart of the SLI lies the subject language semantics, which are captured through 3 functions:</p> <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="nf">semantics</span> <span class="o">(</span><span class="n">C</span> <span class="n">A</span><span class="o">)</span> <span class="o">≜</span>
    <span class="n">initial</span><span class="k">:</span> <span class="kt">set</span> <span class="kt">C</span>
    <span class="n">actions</span><span class="k">:</span> <span class="kt">C</span> <span class="kt">→</span> <span class="kt">set</span> <span class="kt">A</span>
    <span class="n">execute</span><span class="k">:</span> <span class="kt">A</span> <span class="kt">→</span> <span class="kt">C</span> <span class="kt">→</span> <span class="kt">set</span> <span class="kt">C</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>where:</p> <ul> <li><code class="language-plaintext highlighter-rouge">C</code>: is a type capturing the semantic <em>configurations</em> (the execution state) of the subject language;</li> <li><code class="language-plaintext highlighter-rouge">A</code>: is an <em>action</em> type, that classifies all the transition rules of the underlying semantics. In general, an action can be thought as a function from configurations to sets of configurations <code class="language-plaintext highlighter-rouge">action: C → set C</code>;</li> <li><code class="language-plaintext highlighter-rouge">initial: set C</code>: This function defines a set of initial configurations from which the system can start. Allowing multiple initial configurations, allow to capture the <em>initial non-determinism</em> that might be present in the subject language. If the subject language does not have <em>initial non-determinism</em> one can always return a singleton.</li> <li><code class="language-plaintext highlighter-rouge">actions: C → set A</code>: This mapping relates each configuration to a set of executable actions, the set of functions <code class="language-plaintext highlighter-rouge">C → set C</code> that can be executed in a configuration <code class="language-plaintext highlighter-rouge">c ∈ C</code>. Allowing multiple actions to be enabled in a configuration, allows capturing the potential <em>action non-determinism</em> of the subject language. This is typically the case for concurrent languages, where two threads (actors, state-machines) have enabled actions in a given configuration (execution state). A singleton can be returned, when only one action is available;</li> <li><code class="language-plaintext highlighter-rouge">execute: A → C → set C</code>: This functions executes an action <code class="language-plaintext highlighter-rouge">a ∈ A</code> in a specific configuration to obtain the set of resulting configurations. <em>Execution non-determinism</em> is captured by the production of multiple configurations during the action execution. This typically arises when the subject language semantics choses to allow non-deterministic actions (rules). While in principle it is possible to flatten <em>execution non-determinism</em> to <em>action non-determinism</em>, it is sometimes advantageous for a subject language semantics to hide some low-level operational steps in the action functions.</li> </ul> <h2 id="step-evaluation">Step Evaluation</h2> <p>The execution of a subject language semantics, captured through the SLI semantic functions, gives rise to <strong>execution steps</strong>. An <strong>execution step</strong> is a triplet (c₁, a, c₂) from the ternary relation <code class="language-plaintext highlighter-rouge">Steps ⊆ (C x (A | Stutter) x C)</code> of execution steps allowed by the semantics. The steps are usually not explicitly captured by a specification (the exception being raw graphs, in <a href="https://en.wikipedia.org/wiki/Trivial_Graph_Format">TGF</a> format for instance), but they arise during the execution of the semantics.</p> <p>It is important to note that in certain situations the execution will stutter, for instance to allow infinite trace interpretation in case of deadlock, or to allow specification refinement (where an abstract specification will stutter during the execution of small steps in a more refined specification). A stuttering step is a reflexive step on the source configuration (the source and target configuration are the same), and they are tagged by the <code class="language-plaintext highlighter-rouge">Stutter</code> action, which in most cases is external from the suject language semantics (the subject language semantics does not include a <code class="language-plaintext highlighter-rouge">Stutter</code> action). However, for complete observability, the evaluation function needs to see these steps. If stuttering steps are present, a termination condition is needed to distinguish between normal termination and deadlock. In this case, normal termination is a stuttering step that satifies the termination condition. In other words, an execution terminates when the termination condition <code class="language-plaintext highlighter-rouge">evaluates</code> to true on a stuttering step.</p> <p>The SLI proposes to use an <code class="language-plaintext highlighter-rouge">evaluate: E → (C x (A | Stutter) x C) → V</code> function on <em>execution steps</em>, to isolate the language specific encoding of the configurations and actions from the tools needing to reason about the execution of a semantics. This function hides the implementation details by offering the means to answer queries on an <em>execution step</em> through subject-language specific expressions, in a <strong>diagnosis language</strong>. The <code class="language-plaintext highlighter-rouge">evaluate</code> function evaluates an expression e ∈ E in the context of an <em>execution step</em> (c₁, a, c₂) to produce a value v ∈ V, where <code class="language-plaintext highlighter-rouge">V</code> is a type classifying the set of values used in the subject-language semantics.</p> <p>Note, however, that the values from <code class="language-plaintext highlighter-rouge">V</code> are specific to the subject-language semantics, and that usage-specific transformations might be needed to convert these values to the domain of values needed by the caller of the <code class="language-plaintext highlighter-rouge">evaluate</code> function.</p> <p>The reader, can think of this evaluation function as an extension of an typical <code class="language-plaintext highlighter-rouge">eval</code> function, pioneered by LISP and present in a number of programming languages today. This extension of the typical <code class="language-plaintext highlighter-rouge">eval</code> is necessary to allow richer <em>diagnosis queries</em> without the need to flatten the state-space to a lower-level <a href="https://en.wikipedia.org/wiki/Kripke_structure_(model_checking)">Kripke structure</a>, which would push the actions, and the valuation of (source, target) predicates from the edges to the target configuration view.</p> <h2 id="reduction">Reduction</h2> <p>The <code class="language-plaintext highlighter-rouge">reduce: R → C → ⍺</code> function, of the G∀min∃ SLI, simplifies or collapses configurations into a more abstract representation, denoted by ⍺. This capability aids in analyzing the behavior of the system by simplifying the state-representation. This function allows implementing multiple state-space reduction strategies ranging from precise abstractions like symmetry reduction, and predicate abstraction to brutal under-approximations like bitstate hashing and hashcompaction.</p> <h2 id="projections-of-semantical-entities">Projections of Semantical Entities</h2> <p>Lastly, the SLI provides a way to project various semantical entities:</p> <p><code class="language-plaintext highlighter-rouge">π (C A V ⍺ T)</code>: This set of functions represent the projections of semantical entities, including configurations (<code class="language-plaintext highlighter-rouge">C</code>), actions (<code class="language-plaintext highlighter-rouge">A</code>), evaluation results (<code class="language-plaintext highlighter-rouge">V</code>), reduced forms (<code class="language-plaintext highlighter-rouge">⍺</code>). These projections allow users map the language specific values to a target value domain <code class="language-plaintext highlighter-rouge">T</code> either for user consumption (through pretty-printing) or for further processing in the client context (through data transformations).</p> <h2 id="conclusion">Conclusion</h2> <p>The G∀min∃ Semantic Language Interface (SLI) offers a robust framework for modeling operational semantics, making it a powerful tool for analyzing system behavior. By capturing non-determinism and providing structured methods for evaluation and reduction, the SLI enhances the process of formal verification, ultimately contributing to the development of reliable and well-designed systems.</p> <p>This interface can be viewed as an operational implementation of the more theoretical approach presented in <strong>Omnisemantics</strong> <a href="#1">[1]</a>. In contrast to this approach, the <strong>G∀min∃ SLI</strong> requires the existence of <strong>computably enumerable (c.e.) predicates</strong> for the functions that define the state transitions: <code class="language-plaintext highlighter-rouge">initial</code>, <code class="language-plaintext highlighter-rouge">actions</code>, and <code class="language-plaintext highlighter-rouge">execute</code>. Specifically, the <code class="language-plaintext highlighter-rouge">initial</code> function must be a computably enumerable predicate that can enumerate all possible initial configurations, while the <code class="language-plaintext highlighter-rouge">actions</code> function must enumerate all valid actions available for a given configuration. Additionally, the <code class="language-plaintext highlighter-rouge">execute</code> function needs to be a computably enumerable predicate that enumerates the resulting configurations after executing an action in a given configuration.</p> <p>This requirement for <strong>computable enumerability</strong> may seem like a significant limitation compared to the more general framework of <strong>Omnisemantics</strong>, which does not impose such constraints <a href="#1">[1]</a>. However, these conditions reflect the <em>practical constraints imposed on language semantics by execution environments</em>, where enumerability is often essential to facilitate the exploration of the configuration space. This is particularly true in contexts like execution, debugging, and model-checking. In more theoretical applications, the G∀min∃ SLI could be used without imposing these constraints, but such an approach would sacrifice “executability.”</p> <p>An additional manifestation of this constraint can be seen in the context of <strong>TLA+</strong> <a href="#2">[2]</a>, which, while allowing arbitrary predicates for general specifications and theorem proving, imposes a requirement for at least <strong>computably enumerable (c.e.) predicates</strong> when using <strong>TLC</strong> <a href="#3">[3]</a> for execution, debugging, and model checking. In TLA+, the actions of a specification must be enumerable to enable the effective exploration of state transitions.</p> <p>The requirement for c.e. predicates is <em>necessary</em>, but in some cases, it may not be <em>sufficient</em>. Stronger constraints, such as <em>finitely enumerable predicates</em>, could be needed to ensure practical execution and analysis of specifications (e.g., exhaustive state-space exploration).</p> <h2 id="references">References</h2> <p><a id="1">[1]</a> Arthur Charguéraud, Adam Chlipala, Andres Erbsen, and Samuel Gruetter. 2023. Omnisemantics: Smooth Handling of Nondeterminism. ACM Trans. Program. Lang. Syst. 45, 1, Article 5 (March 2023), 43 pages. https://doi.org/10.1145/3579834</p> <p><a id="1">[2]</a> Leslie Lamport. 1994. The temporal logic of actions. ACM Trans. Program. Lang. Syst. 16, 3 (May 1994), 872–923. https://doi.org/10.1145/177492.177726</p> <p><a id="1">[3]</a> Yuan Yu, Panagiotis Manolios, and Leslie Lamport. 1999. Model Checking TLA+ Specifications. In Proceedings of the 10th IFIP WG 10.5 Advanced Research Working Conference on Correct Hardware Design and Verification Methods (CHARME ‘99). Springer-Verlag, Berlin, Heidelberg, 54–66.</p>]]></content><author><name></name></author><category term="research"/><category term="semantics"/><category term="operational semantics"/><category term="semantics"/><category term="executable models"/><summary type="html"><![CDATA[a brief introduction to the G∀min∃ Semantic Language Interface]]></summary></entry><entry><title type="html">Multiverse Debugging</title><link href="https://teodorov.github.io/blog/2024/multiverse_debugging/" rel="alternate" type="text/html" title="Multiverse Debugging"/><published>2024-10-10T00:00:00+00:00</published><updated>2024-10-10T00:00:00+00:00</updated><id>https://teodorov.github.io/blog/2024/multiverse_debugging</id><content type="html" xml:base="https://teodorov.github.io/blog/2024/multiverse_debugging/"><![CDATA[<p><strong>Multiverse debugging</strong> offers a powerful toolset for addressing the inherent complexity and non-determinism in concurrent systems. It opens new possibilities for developers and researchers to understand, analyze, optimize, and improve system reliability and performance.</p> <p>The concept of the <em>multiverse</em>, though controversial in philosophy <a href="#1">[1]</a> and physics <a href="#2">[2]</a>, has gained traction in psychology <a href="#3">[3]</a> and neurology <a href="#4">[4]</a>, where multiverse analysis addresses the researcher’s degrees of freedom issue <a href="#5">[5]</a>. In mathematics, the multiverse framework is seen in foundational interpretations of set theory <a href="#6">[6]</a>. In engineering, Leslie Lamport’s Temporal Logic of Actions (TLA) <a href="#7">[7]</a> conceptualizes system specifications within an implicit underlying universe. This framework complements Edward Lee’s view on engineering models <a href="#8">[8]</a>, where engineers are seen as creators of their design universes.</p> <p>In computer science, the multiverse concept was first introduced in <a href="#10">[10]</a> to address challenges in debugging concurrent actor programs. <strong>Multiverse debugging</strong> proposes to explore all potential program behaviors, paralleling modal temporal logics and Kripke’s possible worlds interpretations <a href="#9">[9]</a>. The idea of <strong>multiverse debugging</strong> was extended to the formal analysis of behavioral specifications <a href="#11">[11]</a><a href="#12">[12]</a><a href="#13">[13]</a>, where it served as a cohesive metaphor for integrating debugging and model-checking <a href="#11">[11]</a>. This integration enhances breakpoint expressivity <a href="#11">[11]</a> and facilitates interactive analysis of complex systems <a href="#13">[13]</a>. Early scalability concerns <a href="#10">[10]</a> were mitigated by M. Pasquier et al. in <a href="#12">[12]</a>, who demonstrated that <strong>multiverse debugging</strong> could be optimized through the integration of a variety of under-approximation techniques <a href="#14">[14]</a>.</p> <h2 id="references">References</h2> <p><a id="1">[1]</a> S. Friederich, Multiverse Theories: A Philosophical Perspective. Cambridge: Cambridge University Press, 2021.</p> <p><a id="2">[2]</a> John F. Donoghue. The multiverse and particle physics. Annual Review of Nuclear and Particle Science, 66(Volume 66, 2016):1–21, 2016.</p> <p><a id="3">[3]</a> Steegen, S., Tuerlinckx, F., Gelman, A., &amp; Vanpaemel, W. (2016). Increasing Transparency Through a Multiverse Analysis. Perspectives on Psychological Science, 11(5), 702-712. https://doi.org/10.1177/1745691616658637</p> <p><a id="4">[4]</a> Clayson, Peter E. (2024-03-01). “Beyond single paradigms, pipelines, and outcomes: Embracing multiverse analyses in psychophysiology”. International Journal of Psychophysiology. 197: 112311. doi:10.1016/j.ijpsycho.2024.112311. ISSN 0167-8760</p> <p><a id="5">[5]</a> Wicherts, Jelte M.; Veldkamp, Coosje L. S.; Augusteijn, Hilde E. M.; Bakker, Marjan; van Aert, Robbie C. M.; van Assen, Marcel A. L. M. (2016). “Degrees of Freedom in Planning, Running, Analyzing, and Reporting Psychological Studies: A Checklist to Avoid p-Hacking”. Frontiers in Psychology. 7: 1832. doi:10.3389/fpsyg.2016.01832. PMC 5122713. PMID 27933012.</p> <p><a id="6">[6]</a> D. Hamkins, “The Set-theoretic Multiverse,” The Review of Symbolic Logic, vol. 5, no. 3, pp. 416–449, 2012. doi:10.1017/S1755020311000359</p> <p><a id="7">[7]</a> Leslie Lamport. 1994. The temporal logic of actions. ACM Trans. Program. Lang. Syst. 16, 3 (May 1994), 872–923. https://doi.org/10.1145/177492.177726</p> <p><a id="8">[8]</a> Edward A. Lee. 2018. Modeling in engineering and science. Commun. ACM 62, 1 (January 2019), 35–36. https://doi.org/10.1145/3231590.</p> <p><a id="9">[9]</a> Raymond D. Bradley, Norman Swartz, Possible Worlds – An Introduction to Logic and its Philosophy, Hackett Publishing (1979).</p> <p><a id="10">[10]</a> Carmen Torres Lopez, Robbert Gurdeep Singh, Stefan Marr, Elisa Gonzalez Boix, and Christophe Scholliers. Multiverse Debugging: Non-Deterministic Debugging for Non-Deterministic Programs (Brave New Idea Paper). In 33rd European Conference on Object-Oriented Programming (ECOOP 2019). Leibniz International Proceedings in Informatics (LIPIcs), Volume 134, pp. 27:1-27:30, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2019) https://doi.org/10.4230/LIPIcs.ECOOP.2019.27</p> <p><a id="11">[11]</a> Matthias Pasquier, <strong>Ciprian Teodorov</strong>, Frédéric Jouault , Matthias Brun , Luka Le Roux. Temporal Breakpoints for Multiverse Debugging. Software Language Engineering 2023, Oct 2023, Lisbonne, Portugal.</p> <p><a id="12">[12]</a> Matthias Pasquier, <strong>Ciprian Teodorov</strong>, Frédéric Jouault , Matthias Brun , Luka Le Roux. Practical multiverse debugging through user-defined reductions. MODELS ‘22: ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems, Oct 2022, Montreal Quebec Canada, Canada. pp.87-97, ⟨10.1145/3550355.3552447⟩.</p> <p><a id="13">[13]</a> Matthias Pasquier, <strong>Ciprian Teodorov</strong>, Frédéric Jouault , Matthias Brun , Loïc Lagadec. Debugging Paxos in the UML Multiverse. MODELS-C/MoDeVVa, Oct 2023, Västerås, Sweden.</p> <p><a id="14">[14]</a> Radek Pelanek. Reduction and Abstraction Techniques for Model Checking. Ph.D. Thesis, Masaryk University, 2006.</p>]]></content><author><name></name></author><category term="research"/><category term="debugging"/><summary type="html"><![CDATA[a brief introduction to multiverse debugging]]></summary></entry></feed>